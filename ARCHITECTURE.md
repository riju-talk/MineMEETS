# MineMEETS System Architecture

**Production MLOps Architecture for Multimodal RAG System**

---

## ğŸ“ System Overview

MineMEETS is designed as a **production-grade ML pipeline** with clear separation of concerns, deterministic processing, and operational observability. This is **not a research prototype** â€” it's built to demonstrate MLOps best practices.

---

## ğŸ—ï¸ Architecture Layers

### 1. **Ingestion Layer**

**Purpose:** Validate, route, and preprocess raw meeting content

**Components:**
- `coordinator.py` - Orchestrates multimodal ingestion
- `document_processor.py` - Text extraction and chunking
- `audio_agent.py` - Audio transcription via Whisper
- `image_agent.py` - Image embedding via CLIP

**Key Design Decisions:**
- âœ… **Idempotent operations** - Can safely rerun without duplication
- âœ… **Validation first** - File type, size, format checks before processing
- âœ… **Fallback paths** - Graceful degradation on partial failures
- âœ… **Meeting-scoped namespaces** - Isolation per `meeting_id`

**Data Flow:**
```
Raw File Input â†’ Validation â†’ Type Detection â†’ Agent Routing
    â†“
[Text] â†’ DocumentProcessor â†’ Chunks
[Audio] â†’ AudioAgent (Whisper) â†’ Transcription â†’ Chunks
[Image] â†’ ImageAgent (CLIP) â†’ Visual Embeddings
```

---

### 2. **Embedding Layer**

**Purpose:** Generate consistent 512-dimensional embeddings across all modalities

**Components:**
- `SentenceTransformer` (CLIP ViT-B/32) for text and images
- Whisper transcription â†’ text embeddings
- Dimensional validation before upsert

**Key Design Decisions:**
- âœ… **Unified embedding space** - All modalities use CLIP's shared space
- âœ… **Batch processing** - Embeddings generated in batches for efficiency
- âœ… **Dimension checks** - Strict validation (must be 512-dim)
- âœ… **Error isolation** - Failed embeddings don't block entire batch

**Embedding Pipeline:**
```
Text â†’ SentenceTransformer â†’ [512-dim vector]
Audio â†’ Whisper â†’ Text â†’ SentenceTransformer â†’ [512-dim vector]
Image â†’ CLIP Encoder â†’ [512-dim vector]
```

---

### 3. **Vector Storage Layer**

**Purpose:** Reliable, scalable storage and retrieval of embeddings

**Components:**
- `pinecone_db.py` - Pinecone client wrapper
- Namespace strategy for multi-tenancy
- Metadata schema for filtering

**Key Design Decisions:**
- âœ… **Namespace per meeting** - Enables per-meeting operations
- âœ… **Metadata-rich schema** - Supports filtering, debugging, auditing
- âœ… **Batch upserts** - Configurable batch size (default: 100)
- âœ… **Safe deletion** - Namespace-scoped for rollback

**Pinecone Schema:**
```json
{
  "id": "meeting_20260131_chunk_14",
  "values": [0.12, -0.45, ...],  // 512-dim
  "metadata": {
    "meeting_id": "meeting_20260131",
    "modality": "text",
    "type": "text_chunk",
    "chunk_index": 14,
    "position": 14,
    "timestamp_start": 120,  // For audio
    "timestamp_end": 145,
    "source": "transcript",
    "text": "Original text content..."
  }
}
```

---

### 4. **Retrieval Layer**

**Purpose:** Hybrid search strategies for high-quality context retrieval

**Components:**
- `multimodal_rag.py` - Retrieval logic
- `MultimodalRetriever` - Hybrid search orchestration

**Key Design Decisions:**
- âœ… **Hybrid search** - Semantic + keyword + query expansion
- âœ… **Deterministic ranking** - No stochastic behavior
- âœ… **Modality awareness** - Cross-modal context assembly
- âœ… **Deduplication** - Remove duplicate results
- âœ… **Score normalization** - Consistent ranking across strategies

**Retrieval Strategies:**

1. **Semantic Search** (Primary)
   - Vector similarity via Pinecone
   - Returns top-10 most similar chunks
   - Boost factor: 1.0

2. **Keyword Search** (Recall Enhancement)
   - Extract keywords from query
   - Search for each keyword
   - Boost factor: 0.8

3. **Query Expansion** (General Questions)
   - Detect general queries ("summary", "overview")
   - Expand to broader search terms
   - Boost factor: 0.6

**Hybrid Scoring:**
```python
hybrid_score = (
    original_score *
    search_type_boost *
    content_type_boost *
    position_boost *
    keyword_overlap_boost
)
```

---

### 5. **Inference Layer**

**Purpose:** Stateless LLM inference with context assembly

**Components:**
- `llm.py` - Ollama HTTP client
- `qa_agent.py` - Q&A orchestration
- Context formatting and prompt engineering

**Key Design Decisions:**
- âœ… **Local inference** - No external API dependencies
- âœ… **Stateless execution** - Each query is independent
- âœ… **Context constraints** - Token limit management
- âœ… **Source attribution** - Track which chunks contributed
- âœ… **Modality indicators** - LLM knows source modality

**Prompt Structure:**
```
System Instructions
   â†“
Available Modalities: [text, audio, image]
   â†“
Context by Modality:
  - TEXT TRANSCRIPTS: [chunks...]
  - AUDIO TRANSCRIPTION: [segments...]
  - IMAGE DESCRIPTIONS: [descriptions...]
   â†“
User Question
   â†“
Answer Guidelines
```

---

### 6. **API/UI Layer**

**Purpose:** Thin client for user interaction

**Components:**
- `app.py` - Gradio interface
- RESTful design (could be FastAPI in future)

**Key Design Decisions:**
- âœ… **Thin client** - Business logic stays in agents
- âœ… **Async-friendly** - Non-blocking operations
- âœ… **Simple deployment** - Single Python file
- âœ… **Production-ready** - Health checks, error handling

---

## ğŸ“Š Operational Characteristics

### Observability

**Implemented:**
- âœ… Structured logging (Python logging module)
- âœ… Processing success/failure tracking
- âœ… Embedding dimension validation
- âœ… Upsert count metrics
- âœ… Retrieval latency logging

**Planned:**
- ğŸ”„ Prometheus metrics export
- ğŸ”„ Distributed tracing (OpenTelemetry)
- ğŸ”„ Dashboard (Grafana)

### Reliability

**Patterns:**
- âœ… **Idempotency** - Safe to retry operations
- âœ… **Graceful degradation** - Partial failures don't block entire pipeline
- âœ… **Validation gates** - Catch errors early
- âœ… **Namespace isolation** - Failures isolated per meeting

### Scalability

**Current State:**
- âœ… Batch processing (chunking, embedding, upsert)
- âœ… Pinecone handles vector scaling
- âœ… Stateless services (easy horizontal scaling)

**Future Improvements:**
- ğŸ”„ Async ingestion workers
- ğŸ”„ Queue-based processing (Celery/RQ)
- ğŸ”„ Distributed inference

---

## ğŸ”„ Data Flow (End-to-End)

```
User Upload (Gradio)
    â†“
File Saved to data/raw/
    â†“
Coordinator Receives File
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Text File     â”‚   Audio File     â”‚   Image File    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                 â†“                  â†“
  DocumentProcessor   AudioAgent        ImageAgent
         â†“                 â†“                  â†“
    Text Chunks      Transcription      Visual Embed
         â†“                 â†“                  â†“
  SentenceTransformer  â†’ Text Chunks   CLIP Encoder
         â†“                 â†“                  â†“
     Embeddings       Embeddings        Embeddings
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
                PineconeDB.upsert_documents()
                        â†“
                Pinecone Index
               (namespace=meeting_id)
                        â†“
                  [QUERY PHASE]
                        â†“
                User asks question
                        â†“
              MultimodalRetriever
                 (Hybrid Search)
                        â†“
            Ranked Context Chunks
                        â†“
                Context Assembly
            (modality-aware formatting)
                        â†“
                  LLM (Ollama)
                        â†“
                Generated Answer
                        â†“
                 User receives
            Answer + Source Attribution
```

---

## ğŸ›¡ï¸ Error Handling Strategy

### Validation Failures
- **Where:** Ingestion layer
- **Action:** Reject with clear error message
- **Impact:** No downstream processing

### Processing Failures
- **Where:** Agent layer (audio/image)
- **Action:** Log error, skip chunk, continue batch
- **Impact:** Partial meeting processing

### Embedding Failures
- **Where:** Embedding layer
- **Action:** Dimension check fails â†’ log and skip
- **Impact:** Chunk excluded from index

### Retrieval Failures
- **Where:** Query time
- **Action:** Return empty context, inform user
- **Impact:** Degraded answer quality

### LLM Failures
- **Where:** Inference layer
- **Action:** Timeout or error â†’ return fallback message
- **Impact:** User notified of failure

---

## ğŸ” Security Considerations

- âœ… API keys via environment variables (not hardcoded)
- âœ… No external API calls (local Ollama)
- âœ… File validation before processing
- âœ… Container isolation (Docker)
- ğŸ”„ **TODO:** Authentication/authorization for multi-user
- ğŸ”„ **TODO:** Data encryption at rest
- ğŸ”„ **TODO:** Rate limiting on API endpoints

---

## ğŸ“¦ Deployment Patterns

### Local Development
```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python app.py
```

### Docker (Single Container)
```bash
docker build -t minemeets:latest .
docker run -p 7860:7860 --env-file .env minemeets:latest
```

### Docker Compose (Production-like)
```bash
docker-compose up --build
```

### Future: Kubernetes
- ğŸ”„ Deployment manifests
- ğŸ”„ Service mesh (Istio)
- ğŸ”„ Horizontal pod autoscaling
- ğŸ”„ Persistent volume for data/

---

## ğŸ§ª Testing Strategy

### Unit Tests
- âœ… `test_document_processor.py` - Chunking logic
- âœ… `test_pinecone_db.py` - Vector operations
- âœ… `test_llm.py` - LLM interface

### Integration Tests
- ğŸ”„ End-to-end ingestion pipeline
- ğŸ”„ Query â†’ retrieval â†’ inference flow
- ğŸ”„ Multi-file processing

### Performance Tests
- ğŸ”„ Large file processing time
- ğŸ”„ Query latency under load
- ğŸ”„ Concurrent user simulation

---

## ğŸ“ˆ Monitoring & Metrics

### Key Metrics to Track

**Ingestion:**
- Files processed per minute
- Processing failures (by type)
- Average chunk count per file
- Embedding generation time

**Storage:**
- Total vectors in index
- Namespace count (= meeting count)
- Upsert latency
- Index size

**Retrieval:**
- Query latency (p50, p95, p99)
- Context chunk count per query
- Hybrid search breakdown (semantic/keyword/expanded)
- Empty result rate

**Inference:**
- LLM generation time
- Token usage per query
- Error rate
- User satisfaction (if feedback collected)

---

## ğŸ”„ Reprocessing & Maintenance

### Per-Meeting Reprocessing
```python
# Delete old meeting data
db.delete_vectors(namespace=meeting_id, delete_all=True)

# Reprocess meeting
coordinator.process_meeting(meeting_data)
```

### Selective Modality Reindexing
```python
# Delete only text chunks
db.delete_vectors(
    namespace=meeting_id,
    filter={"type": "text_chunk"}
)

# Reprocess only text
# ... (selective processing)
```

### Full Database Flush
```python
# âš ï¸ DANGEROUS - deletes everything
db.flush_database()
```

---

## ğŸš€ Future Enhancements

### High Priority
- [ ] Add FastAPI for RESTful API
- [ ] Implement proper authentication
- [ ] Add Prometheus metrics
- [ ] Create Kubernetes manifests

### Medium Priority
- [ ] Add speaker diarization to audio
- [ ] Implement image OCR for text extraction
- [ ] Add meeting comparison feature
- [ ] Build analytics dashboard

### Research/Experimental
- [ ] Multi-turn conversation support
- [ ] Real-time streaming ingestion
- [ ] Automatic meeting summarization on upload
- [ ] Cross-meeting search

---

## ğŸ“š References

**Technologies:**
- [Pinecone Documentation](https://docs.pinecone.io/)
- [Whisper Paper](https://arxiv.org/abs/2212.04356)
- [CLIP Paper](https://arxiv.org/abs/2103.00020)
- [Gradio Docs](https://gradio.app/docs/)
- [Ollama Docs](https://ollama.com/docs/)

**MLOps Best Practices:**
- [Google MLOps Whitepaper](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)
- [ML Systems Design](https://github.com/chiphuyen/machine-learning-systems-design)

---

**Document Version:** 1.0  
**Last Updated:** January 31, 2026  
**Author:** MineMEETS Development Team
